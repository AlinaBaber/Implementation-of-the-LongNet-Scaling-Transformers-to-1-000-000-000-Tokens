{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0843e49b",
      "metadata": {
        "id": "0843e49b",
        "outputId": "733057a4-94e9-46fc-ec8a-4f21d4ec1fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-12-01 13:57:22,098] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "from transformers import GPT2Tokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import gutenberg\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from datasets import load_dataset\n",
        "import deepspeed\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from deepspeed.ops.adam import FusedAdam\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d31ff49b",
      "metadata": {
        "id": "d31ff49b"
      },
      "outputs": [],
      "source": [
        "class DilatedAttention(nn.Module):\n",
        "    def __init__(self, embed_size, heads, segment_length, dilation_rate):\n",
        "        super(DilatedAttention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_size // heads\n",
        "        self.segment_length = segment_length\n",
        "        self.dilation_rate = dilation_rate\n",
        "\n",
        "        assert embed_size % heads == 0, \"Embed size must be divisible by number of heads\"\n",
        "\n",
        "        self.values = nn.Linear(self.head_dim, self.head_dim)\n",
        "        self.keys = nn.Linear(self.head_dim, self.head_dim)\n",
        "        self.queries = nn.Linear(self.head_dim, self.head_dim)\n",
        "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
        "\n",
        "    def forward(self, values, keys, query):\n",
        "        N = query.shape[0]\n",
        "\n",
        "        # Split the embedding into self.heads different pieces\n",
        "        values = self.split_heads(self.values(values), N)\n",
        "        keys = self.split_heads(self.keys(keys), N)\n",
        "        queries = self.split_heads(self.queries(query), N)\n",
        "\n",
        "        # Sparsify (dilate) the segments\n",
        "        values = self.dilate_segments(values)\n",
        "        keys = self.dilate_segments(keys)\n",
        "        queries = self.dilate_segments(queries)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        attention = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
        "        attention = F.softmax(attention / (self.head_dim ** 0.5), dim=-1)\n",
        "\n",
        "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
        "            N, -1, self.heads * self.head_dim\n",
        "        )\n",
        "\n",
        "        return self.fc_out(out)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        # Split the last dimension into (heads, head_dim)\n",
        "        return x.view(batch_size, -1, self.heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def dilate_segments(self, tensor):\n",
        "        # Implement the dilation logic\n",
        "        batch_size, heads, seq_length, head_dim = tensor.shape\n",
        "        new_seq_length = seq_length // self.dilation_rate  # Adjusted for dilation\n",
        "        dilated_tensor = torch.zeros(batch_size, heads, new_seq_length, head_dim, device=tensor.device)\n",
        "\n",
        "        for i in range(0, seq_length, self.dilation_rate):\n",
        "            dilated_tensor[:, :, i // self.dilation_rate, :] = tensor[:, :, i, :]\n",
        "\n",
        "        return dilated_tensor\n",
        "\n",
        "class MultiHeadDilatedAttention(nn.Module):\n",
        "    def __init__(self, embed_size, num_heads, segment_length, dilation_rates):\n",
        "        super(MultiHeadDilatedAttention, self).__init__()\n",
        "        self.heads = nn.ModuleList([])\n",
        "        self.embed_size = embed_size\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        for dilation_rate in dilation_rates:\n",
        "            # Each head will have its own unique dilation rate\n",
        "            self.heads.append(DilatedAttention(embed_size, 1, segment_length, dilation_rate))\n",
        "\n",
        "        # Output linear layer to combine the heads\n",
        "        self.fc_out = nn.Linear(embed_size * len(dilation_rates), embed_size)\n",
        "\n",
        "    def forward(self, values, keys, query):\n",
        "        attention_outs = [head(values, keys, query) for head in self.heads]\n",
        "\n",
        "        # Concatenate outputs from different heads\n",
        "        out = torch.cat(attention_outs, dim=-1)\n",
        "\n",
        "        # Final linear layer to project back to the original embedding size\n",
        "        out = self.fc_out(out)\n",
        "\n",
        "        return out\n",
        "#my added cachedMemory bank class here\n",
        "class CachedMemoryBank(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, memory_dim):\n",
        "        super(CachedMemoryBank, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.memory_key = nn.Linear(embedding_dim, memory_dim)\n",
        "        self.memory_value = nn.Linear(embedding_dim, memory_dim)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        keys = self.memory_key(embedded)\n",
        "        values = self.memory_value(embedded)\n",
        "        return keys, values\n",
        "#ended here\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, hidden_size, num_heads, feedforward_size, memory_bank, dilation=1, dropout_rate=0.1, dilation_rate=[1,2,3,4]):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        # Multi-head dilated self-attention layer\n",
        "        self.dilated_attention = MultiHeadDilatedAttention(hidden_size, num_heads, dilation, dilation_rate)\n",
        "\n",
        "        # Layer normalization\n",
        "        self.norm1 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        # Position-wise feedforward network\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(hidden_size, feedforward_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_size, hidden_size)\n",
        "        )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.norm2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Memory Bank\n",
        "        self.memory_bank = memory_bank  # <-- Check this line\n",
        "\n",
        "        # Create an instance of CachedMemoryBank\n",
        "        memory_dim = 2048\n",
        "        self.memory_bank = CachedMemoryBank(vocab_size, embedding_dim, memory_dim)\n",
        "\n",
        "    def forward(self, inputs, attention_mask=None):\n",
        "\n",
        "        keys, values = self.memory_bank(input_ids)  # Adjust this line according to your implementation\n",
        "        attention_output = self.dilated_attention(keys, values, inputs)\n",
        "        attention_output = self.dropout(attention_output) + inputs\n",
        "        attention_output = self.norm1(attention_output)\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        ff_output = self.feedforward(attention_output)\n",
        "        ff_output = self.dropout(ff_output) + attention_output\n",
        "        ff_output = self.norm2(ff_output)\n",
        "\n",
        "        return ff_output\n",
        "\n",
        "\n",
        "\n",
        "class LargeLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, feedforward_size, dilation=1, dropout_rate=0.1, max_sequence_length=512):\n",
        "        super(LargeLanguageModel, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(hidden_dim, num_heads, feedforward_size, memory_bank=CachedMemoryBank(vocab_size, embedding_dim, hidden_dim), dilation=dilation, dropout_rate=dropout_rate)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        transformer_output = embedded\n",
        "\n",
        "        for block in self.transformer_blocks:\n",
        "            transformer_output = block(transformer_output, attention_mask)\n",
        "\n",
        "        # Reshape the transformer output before passing through the linear layer\n",
        "        batch_size, seq_length, hidden_dim = transformer_output.size()\n",
        "        transformer_output = transformer_output.view(batch_size * seq_length, hidden_dim)\n",
        "\n",
        "        logits = self.linear(transformer_output)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate_text(self, input_ids, max_length, temperature=1.0, top_k=None, top_p=None):\n",
        "        # Clone the input_ids to avoid modifying the original\n",
        "        generated_ids = input_ids.clone()\n",
        "\n",
        "        # Loop to generate text up to max_length\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass to get logits for the next token\n",
        "            logits = self.forward(generated_ids)\n",
        "\n",
        "            # Apply temperature for token sampling\n",
        "            logits = logits[-1, :] / temperature\n",
        "\n",
        "            # Sampling logic based on top_k and top_p\n",
        "            if top_k is not None:\n",
        "                # Apply top-k sampling\n",
        "                logits, indices = torch.topk(logits, top_k)\n",
        "                probs = torch.softmax(logits, dim=-1)\n",
        "                predicted_id = torch.multinomial(probs, num_samples=1).squeeze()\n",
        "            elif top_p is not None:\n",
        "                # Apply nucleus (top-p) sampling\n",
        "                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "                cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "                sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                sorted_indices_to_remove[:, 1:] = sorted_indices_to_remove[:, :-1]\n",
        "                sorted_indices_to_remove[:, 0] = 0\n",
        "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "                logits[:, indices_to_remove] = float('-inf')\n",
        "                probs = torch.softmax(logits, dim=-1)\n",
        "                predicted_id = torch.multinomial(probs, num_samples=1).squeeze()\n",
        "            else:\n",
        "                # Regular softmax-based sampling\n",
        "                probs = torch.softmax(logits, dim=-1)\n",
        "                predicted_id = torch.multinomial(probs, num_samples=1).squeeze()\n",
        "\n",
        "            # Append the predicted_id to generated_ids\n",
        "            generated_ids = torch.cat((generated_ids, predicted_id.unsqueeze(0).unsqueeze(0)), dim=1)\n",
        "\n",
        "            # Check if the generated token is the end token\n",
        "            if predicted_id == self.vocab_size - 1:\n",
        "                break\n",
        "\n",
        "        return generated_ids\n",
        "\n",
        "\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, corpus_file, max_vocab_size=5000, special_tokens=None):\n",
        "        self.corpus_file = corpus_file\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.special_tokens = special_tokens or ['<PAD>', '<UNK>', '<START>', '<END>']\n",
        "        self.vocab = {}\n",
        "        self.reverse_vocab = {}\n",
        "        self.build_vocab()\n",
        "\n",
        "    def build_vocab(self):\n",
        "        word_counter = collections.Counter()\n",
        "        special_tokens = self.special_tokens\n",
        "\n",
        "        with open(self.corpus_file, 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                words = line.strip().split()\n",
        "                word_counter.update(words)\n",
        "\n",
        "        most_common = word_counter.most_common(self.max_vocab_size - len(special_tokens))\n",
        "\n",
        "        self.vocab = {word: idx + len(special_tokens) for idx, (word, _) in enumerate(most_common)}\n",
        "        self.reverse_vocab = {idx: word for word, idx in self.vocab.items()}\n",
        "\n",
        "        for idx, token in enumerate(special_tokens):\n",
        "            self.vocab[token] = idx\n",
        "            self.reverse_vocab[idx] = token\n",
        "\n",
        "    def encode(self, text, add_special_tokens=True):\n",
        "        tokens = text.strip().split()\n",
        "        if add_special_tokens:\n",
        "            tokens = ['<START>'] + tokens + ['<END>']\n",
        "        token_ids = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
        "        return token_ids\n",
        "\n",
        "    def decode(self, token_ids, skip_special_tokens=True):\n",
        "        tokens = [self.reverse_vocab.get(token_id, '<UNK>') for token_id in token_ids]\n",
        "        if skip_special_tokens:\n",
        "            tokens = [token for token in tokens if token not in ['<PAD>', '<START>', '<END>']]\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    def pad_sequences(self, sequences, max_length, padding_token='<PAD>'):\n",
        "        padded_sequences = []\n",
        "        for seq in sequences:\n",
        "            if len(seq) < max_length:\n",
        "                seq += [self.vocab.get(padding_token, self.vocab['<UNK>'])] * (max_length - len(seq))\n",
        "            padded_sequences.append(seq)\n",
        "        return padded_sequences\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "class LanguageModelDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_sequence_length, batch_size, sample_size):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        self.sample_size = sample_size\n",
        "\n",
        "    def DataTokenization(self, text, max_sequence_length):\n",
        "        value = self.tokenizer.encode(text, add_special_tokens=False)\n",
        "        if len(value) > max_sequence_length:\n",
        "            value = value[:max_sequence_length]\n",
        "        else:\n",
        "            value = value + [self.tokenizer.pad_token_id] * (max_sequence_length - len(value))\n",
        "        return value\n",
        "\n",
        "    def TrainDataPreprocess(self, max_sequence_length, sample_size):\n",
        "        # Extract the columns 'system_prompt', 'question', and 'response'\n",
        "        system_prompts = self.dataset['train']['system_prompt']\n",
        "        questions = self.dataset['train']['question']\n",
        "        responses = self.dataset['train']['response']\n",
        "\n",
        "        # Preprocess and pad the sequences\n",
        "        preprocessed_data = []\n",
        "        for i in range(sample_size):\n",
        "            submax_sequence_length = max_sequence_length // 2\n",
        "            padded_system_prompt = self.DataTokenization(system_prompts[i], submax_sequence_length)\n",
        "            padded_question = self.DataTokenization(questions[i], submax_sequence_length)\n",
        "            padded_response = self.DataTokenization(responses[i], max_sequence_length)\n",
        "            preprocessed_data.append({\n",
        "                'system_prompt': padded_system_prompt,\n",
        "                'question': padded_question,\n",
        "                'response': padded_response\n",
        "            })\n",
        "\n",
        "        # Convert the preprocessed data to tensors\n",
        "        system_prompt_tensors = torch.tensor([item['system_prompt'] for item in preprocessed_data], dtype=torch.long)\n",
        "        question_tensors = torch.tensor([item['question'] for item in preprocessed_data], dtype=torch.long)\n",
        "        response_tensors = torch.tensor([item['response'] for item in preprocessed_data], dtype=torch.long)\n",
        "\n",
        "        # Concatenate system_prompts and questions along the appropriate dimension\n",
        "        input_ids = torch.cat((system_prompt_tensors, question_tensors), dim=1)\n",
        "        response_tensors = response_tensors.to(dtype=torch.long)\n",
        "\n",
        "        # Create DataLoader with the preprocessed tensors\n",
        "        data = torch.utils.data.TensorDataset(input_ids, response_tensors)\n",
        "        return data\n",
        "\n",
        "    def TestDataPreprocess(self, max_sequence_length, sample_size):\n",
        "        # Extract the columns 'system_prompt', 'question', and 'response'\n",
        "        system_prompts = self.dataset['test']['system_prompt']\n",
        "        questions = self.dataset['test']['question']\n",
        "        responses = self.dataset['test']['response']\n",
        "\n",
        "        # Preprocess and pad the sequences\n",
        "        preprocessed_data = []\n",
        "        for i in range(sample_size):\n",
        "            submax_sequence_length = max_sequence_length // 2\n",
        "            padded_system_prompt = self.DataTokenization(system_prompts[i], submax_sequence_length)\n",
        "            padded_question = self.DataTokenization(questions[i], submax_sequence_length)\n",
        "            padded_response = self.DataTokenization(responses[i], max_sequence_length)\n",
        "            preprocessed_data.append({\n",
        "                'system_prompt': padded_system_prompt,\n",
        "                'question': padded_question,\n",
        "                'response': padded_response\n",
        "            })\n",
        "\n",
        "        # Convert the preprocessed data to tensors\n",
        "        system_prompt_tensors = torch.tensor([item['system_prompt'] for item in preprocessed_data], dtype=torch.long)\n",
        "        question_tensors = torch.tensor([item['question'] for item in preprocessed_data], dtype=torch.long)\n",
        "        response_tensors = torch.tensor([item['response'] for item in preprocessed_data], dtype=torch.long)\n",
        "\n",
        "        # Concatenate system_prompts and questions along the appropriate dimension\n",
        "        input_ids = torch.cat((system_prompt_tensors, question_tensors), dim=1)\n",
        "        response_tensors = response_tensors.to(dtype=torch.long)\n",
        "\n",
        "        # Create DataLoader with the preprocessed tensors\n",
        "        data = torch.utils.data.TensorDataset(input_ids, response_tensors)\n",
        "        return data\n",
        "\n",
        "    def DataDivision(self, data, test_size=0.2, random_state=42):\n",
        "        # Split the data into training and validation sets\n",
        "        train_data, val_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        # Create DataLoader for training data\n",
        "        train_dataloader = DataLoader(train_data, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        # Create DataLoader for validation data\n",
        "        validation_dataloader = DataLoader(val_data, batch_size=self.batch_size, shuffle=False)\n",
        "        return train_dataloader, validation_dataloader\n",
        "\n",
        "    def DataDivision2(self, data, test_size=0.2, random_state=42):\n",
        "        # Split the data into training and validation sets\n",
        "        train_data, val_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    #     # Create DataLoader for training data\n",
        "    #     train_dataloader = DataLoader(train_data, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    #     # Create DataLoader for validation data\n",
        "    #     validation_dataloader = DataLoader(val_data, batch_size=self.batch_size, shuffle=False)\n",
        "        return train_data, val_data\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"shirsh10mall/LLM_Instruct_Learning_Project_Preprocessed_Tokenized_Open_Orca_Dataset_Flan_T5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a60145ec",
      "metadata": {
        "id": "a60145ec"
      },
      "outputs": [],
      "source": [
        "embed_size = 768  # Example embedding size\n",
        "num_heads = 4     # Number of heads\n",
        "segment_length = 16  # Segment length for dilated attention\n",
        "dilation_rates = [1, 2, 3, 4]  # Dilation rates for each head\n",
        "\n",
        "# Ensure the length of dilation_rates matches num_heads\n",
        "assert len(dilation_rates) == num_heads, \"Length of dilation_rates must be equal to num_heads\"\n",
        "\n",
        "# Create an instance of MultiHeadDilatedAttention\n",
        "multi_head_dilated_attention = MultiHeadDilatedAttention(embed_size, num_heads, segment_length, dilation_rates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a134fa0",
      "metadata": {
        "id": "8a134fa0",
        "outputId": "2a97a9e0-8553-44bc-cdfe-da439064543a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a LanguageModelDataset and LargeLanguageModel classes defined somewhere\n",
        "max_sequence_length = 4096\n",
        "sample_size = 230318\n",
        "batch_size = 3  # Adjusted for 3 GPUs\n",
        "LDS = LanguageModelDataset(dataset, tokenizer, max_sequence_length, batch_size, sample_size)\n",
        "\n",
        "# Preprocess the data\n",
        "data = LDS.TrainDataPreprocess(max_sequence_length, sample_size)\n",
        "train_dataset, validation_dataset = LDS.DataDivision2(data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab4c094d",
      "metadata": {
        "id": "ab4c094d"
      },
      "outputs": [],
      "source": [
        "# Create an instance of your model\n",
        "vocab_size = 2048\n",
        "embedding_dim = 768\n",
        "hidden_dim = 768\n",
        "num_layers = 12\n",
        "num_heads = 12\n",
        "feedforward_size = 2048\n",
        "dilation = 4\n",
        "dropout_rate = 0.1\n",
        "max_sequence_length = 2048\n",
        "model = LargeLanguageModel(vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, feedforward_size, dilation, dropout_rate, max_sequence_length)\n",
        "# model2= DeepSpeedTrainer(model=model,train_dataloader=train_dataloader,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88d99e0",
      "metadata": {
        "id": "f88d99e0",
        "outputId": "ab4565e0-9e2c-46b7-938e-4c522656d8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-12-01 14:04:35,086] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown\n",
            "[2023-12-01 14:04:35,088] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2023-12-01 14:04:35,089] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
            "[2023-12-01 14:04:36,227] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.17.0.2, master_port=29500\n",
            "[2023-12-01 14:04:36,230] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use).\n",
            "[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).\n",
            "[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m      2\u001b[0m deepspeed_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp32\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     }\u001b[39;00m\n\u001b[1;32m     65\u001b[0m }\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Initialize DeepSpeed\\\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#Returns:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# A tuple of ``engine``, ``optimizer``, ``training_dataloader``, ``lr_scheduler``\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m deep_model,deep_optimizer, deep_train_loader, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdeepspeed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepspeed_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/deepspeed/__init__.py:135\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_params)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comm \u001b[38;5;28;01mas\u001b[39;00m dist\n\u001b[1;32m    134\u001b[0m dist_backend \u001b[38;5;241m=\u001b[39m get_accelerator()\u001b[38;5;241m.\u001b[39mcommunication_backend_name()\n\u001b[0;32m--> 135\u001b[0m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_distributed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_init_required\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_init_required\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Set config using config_params for backwards compat\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m config_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/deepspeed/comm/comm.py:670\u001b[0m, in \u001b[0;36minit_distributed\u001b[0;34m(dist_backend, auto_mpi_discovery, distributed_port, verbose, timeout, init_method, dist_init_required, config, rank, world_size)\u001b[0m\n\u001b[1;32m    668\u001b[0m     utils\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitializing TorchBackend in DeepSpeed with backend \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dist_backend))\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# Create a torch backend object, initialize torch distributed, and assign to cdb\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m cdb \u001b[38;5;241m=\u001b[39m \u001b[43mTorchBackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/deepspeed/comm/torch.py:120\u001b[0m, in \u001b[0;36mTorchBackend.__init__\u001b[0;34m(self, backend, timeout, init_method, rank, world_size, name)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Future functionality to support ds.initialize() on a single GPU\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# The idea is to fake that dist backend is initialized even when\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# it is not so we can run on a single GPU without doing any init_process_group\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_gpu_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/deepspeed/comm/torch.py:146\u001b[0m, in \u001b[0;36mTorchBackend.init_process_group\u001b[0;34m(self, backend, timeout, init_method, rank, world_size)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_process_group\u001b[39m(\u001b[38;5;28mself\u001b[39m, backend, timeout, init_method, rank, world_size):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized():\n\u001b[0;32m--> 146\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43minit_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musing_mpi \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mget_backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmpi\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:754\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     rendezvous_iterator \u001b[38;5;241m=\u001b[39m rendezvous(\n\u001b[1;32m    752\u001b[0m         init_method, rank, world_size, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    753\u001b[0m     )\n\u001b[0;32m--> 754\u001b[0m     store, rank, world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrendezvous_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m     store\u001b[38;5;241m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/distributed/rendezvous.py:246\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m master_addr \u001b[38;5;241m=\u001b[39m _get_env_or_raise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMASTER_ADDR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m master_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(_get_env_or_raise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMASTER_PORT\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 246\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c10d_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (store, rank, world_size)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# If this configuration is invalidated, there is nothing we can do about it\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/distributed/rendezvous.py:177\u001b[0m, in \u001b[0;36m_create_c10d_store\u001b[0;34m(hostname, port, rank, world_size, timeout)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     start_daemon \u001b[38;5;241m=\u001b[39m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTCPStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhostname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_daemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_tenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use)."
          ]
        }
      ],
      "source": [
        "# DeepSpeed setup\n",
        "deepspeed_config = {\n",
        "    \"fp32\": {\n",
        "        \"enabled\": True,\n",
        "        \"loss_scale\": 0,\n",
        "        \"loss_scale_window\": 1000,\n",
        "        \"initial_scale_power\": 16,\n",
        "        \"hysteresis\": 2,\n",
        "        \"min_loss_scale\": 1\n",
        "    },\n",
        "\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"params\": {\n",
        "            \"lr\": 0.001,\n",
        "            \"betas\": (0.9, 0.99),\n",
        "            \"eps\": 1e-8,\n",
        "            \"weight_decay\": 3e-7\n",
        "        }\n",
        "    },\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"WarmupLR\",\n",
        "        \"params\": {\n",
        "            \"warmup_min_lr\": 0,\n",
        "            \"warmup_max_lr\": 0.001,\n",
        "            \"warmup_num_steps\": 1000\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 3,\n",
        "        \"offload_optimizer\": {\n",
        "            \"device\": \"cpu\",\n",
        "            \"pin_memory\": True\n",
        "        },\n",
        "        \"offload_param\": {\n",
        "            \"device\": \"cpu\",\n",
        "            \"pin_memory\": True,\n",
        "            \"buffer_count\": 5,\n",
        "            \"buffer_size\": 1e8,\n",
        "            \"max_in_cpu\": 1e9\n",
        "        },\n",
        "        \"overlap_comm\": True,\n",
        "        \"contiguous_gradients\": True,\n",
        "        \"sub_group_size\": 1e8,\n",
        "        \"reduce_bucket_size\": 2e8,\n",
        "        \"stage3_prefetch_bucket_size\": 1e8,\n",
        "        \"stage3_param_persistence_threshold\": 1e7,\n",
        "        \"stage3_max_live_parameters\": 3e8,\n",
        "        \"stage3_max_reuse_distance\": 2e7,\n",
        "        \"stage3_gather_16bit_weights_on_model_save\": True\n",
        "    },\n",
        "\n",
        "    \"gradient_accumulation_steps\": 3,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"steps_per_print\": 2000,\n",
        "    \"train_batch_size\": 9,\n",
        "    \"train_micro_batch_size_per_gpu\": 3,\n",
        "    \"wall_clock_breakdown\": False,\n",
        "\n",
        "    # Include the data_types configuration\n",
        "#     \"data_types\": {\n",
        "#         \"grad_accum_dtype\": [\"fp32\", \"fp16\", \"bf16\"]\n",
        "#     }\n",
        "}\n",
        "\n",
        "# Initialize DeepSpeed\\\n",
        "#Returns:\n",
        "# A tuple of ``engine``, ``optimizer``, ``training_dataloader``, ``lr_scheduler``\n",
        "deep_model,deep_optimizer, deep_train_loader, _ = deepspeed.initialize(model=model, training_data=train_dataset, config=deepspeed_config,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc81a371",
      "metadata": {
        "id": "fc81a371"
      },
      "outputs": [],
      "source": [
        "len(train_dataset),len(deep_train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dacaa0d",
      "metadata": {
        "id": "1dacaa0d"
      },
      "outputs": [],
      "source": [
        "deep_model,deep_train_loader,deep_optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79bdb92e",
      "metadata": {
        "id": "79bdb92e"
      },
      "outputs": [],
      "source": [
        "len(deep_train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e9ab40",
      "metadata": {
        "id": "68e9ab40"
      },
      "outputs": [],
      "source": [
        "for iteration, batch in enumerate(deep_train_loader):\n",
        "    print(batch)\n",
        "    print('----tttt----')\n",
        "    if iteration>2:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c8dfca",
      "metadata": {
        "id": "b1c8dfca"
      },
      "outputs": [],
      "source": [
        "batch2=next(deep_train_loader)\n",
        "batch2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f38a216",
      "metadata": {
        "id": "3f38a216"
      },
      "outputs": [],
      "source": [
        "batch2=next(deep_train_loader)\n",
        "batch2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e924f43",
      "metadata": {
        "id": "5e924f43"
      },
      "outputs": [],
      "source": [
        "len(batch2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fbd6b89",
      "metadata": {
        "id": "7fbd6b89"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7df3ee6",
      "metadata": {
        "id": "d7df3ee6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aa9ccc9",
      "metadata": {
        "id": "9aa9ccc9",
        "outputId": "b1d9d52e-e74a-46ce-9547-f6597c1cc609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are in the training loop !!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [118,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [54,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m response_tensor\u001b[38;5;241m=\u001b[39mresponse_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mdeep_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWEEEEEEEEEEEEEEEEEEEEEEEE ARE HEREEEEEEEE!!!!!!!!!!!!!!!!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), response_tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/deepspeed/utils/nvtx.py:15\u001b[0m, in \u001b[0;36minstrument_w_nvtx.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     14\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_push(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_pop()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret_val\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/engine.py:1818\u001b[0m, in \u001b[0;36mDeepSpeedEngine.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_auto_cast():\n\u001b[1;32m   1816\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cast_inputs_half(inputs)\n\u001b[0;32m-> 1818\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_optimization_partition_weights():\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;66;03m# Disable automated discovery of external parameters\u001b[39;00m\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mmodules():\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
            "Cell \u001b[0;32mIn[11], line 160\u001b[0m, in \u001b[0;36mLargeLanguageModel.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    157\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m embedded\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_blocks:\n\u001b[0;32m--> 160\u001b[0m     transformer_output \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Reshape the transformer output before passing through the linear layer\u001b[39;00m\n\u001b[1;32m    163\u001b[0m batch_size, seq_length, hidden_dim \u001b[38;5;241m=\u001b[39m transformer_output\u001b[38;5;241m.\u001b[39msize()\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
            "Cell \u001b[0;32mIn[11], line 126\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, inputs, attention_mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 126\u001b[0m     keys, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_bank\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust this line according to your implementation\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilated_attention(keys, values, inputs)\n\u001b[1;32m    128\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output) \u001b[38;5;241m+\u001b[39m inputs\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
            "Cell \u001b[0;32mIn[11], line 89\u001b[0m, in \u001b[0;36mCachedMemoryBank.forward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids):\n\u001b[1;32m     88\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_ids)\n\u001b[0;32m---> 89\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_value(embedded)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m keys, values\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
            "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "### New Training Loop\n",
        "#latest one training\n",
        "# Continue with the rest of your training loop\n",
        "num_epochs = 2\n",
        "# Move the model to the GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "#     batch_n=next(deep_train_loader)\n",
        "\n",
        "    for iteration, batch in enumerate(deep_train_loader):\n",
        "        print(\"We are in the training loop !!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        input_ids, response_tensor= batch\n",
        "        input_ids=input_ids.to(device)\n",
        "        response_tensor=response_tensor.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = deep_model(input_ids)\n",
        "\n",
        "        print(\"WEEEEEEEEEEEEEEEEEEEEEEEE ARE HEREEEEEEEE!!!!!!!!!!!!!!!!!!\")\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), response_tensor.view(-1))\n",
        "        print(f'Epoch {epoch+1} Step {iteration+1} | Loss Calculated : {loss}')\n",
        "\n",
        "        #     loss.backward()\n",
        "        # Perform any additional DeepSpeed engine step\n",
        "        deep_model.backward(loss)\n",
        "\n",
        "        ### 1 ### Use model.step() instead of optimizer.step()\n",
        "        deep_model.step()\n",
        "        ### 2 ### deep_optimizer.step()\n",
        "\n",
        "#         # Backward pass\n",
        "#         model.zero_grad()\n",
        "#         loss.backward()\n",
        "\n",
        "#         # Update parameters\n",
        "#         model.step()\n",
        "\n",
        "    # Validation after each epoch\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for val_batch in validation_dataloader:\n",
        "#             val_input_ids = val_batch[0].to(device)\n",
        "#             val_response_tensor = val_batch[1].to(device)\n",
        "\n",
        "#             val_logits = model(val_input_ids)\n",
        "\n",
        "#             # Compute validation loss\n",
        "#             val_loss = model(val_logits, val_response_tensor)\n",
        "\n",
        "#     print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
        "\n",
        "# Save the final model\n",
        "# filepath = 'trained_model.pth'\n",
        "# torch.save(model.state_dict(), filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4509ea7a",
      "metadata": {
        "id": "4509ea7a"
      },
      "outputs": [],
      "source": [
        "#Currently not  using this\n",
        "# Move the model to the GPU\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model = model.to(device)\n",
        "\n",
        "# Continue with the rest of your training loop\n",
        "num_epochs = 10\n",
        "# Move the model to the GPU\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "    for batch in train_dataset:\n",
        "        input_ids = batch[0]#.to(device)\n",
        "        print(input_ids)\n",
        "        response_tensor = batch[1]#.to(device)\n",
        "        #input_ids=input_ids.to(device)\n",
        "        #response_tensor=response_tensor.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(input_ids)\n",
        "\n",
        "        print(\"WEEEEEEEEEEEEEEEEEEEEEEEE ARE HEREEEEEEEE!!!!!!!!!!!!!!!!!!\")\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), response_tensor.view(-1))\n",
        "\n",
        "        # Perform any additional DeepSpeed engine step\n",
        "        model.backward(loss)\n",
        "\n",
        "        model.step()  # Use model.step() instead of optimizer.step()\n",
        "\n",
        "#         # Assuming you have a loss function defined\n",
        "#         loss = model(logits, response_tensor)\n",
        "\n",
        "#         # Backward pass\n",
        "#         model.zero_grad()\n",
        "#         loss.backward()\n",
        "\n",
        "#         # Update parameters\n",
        "#         model.step()\n",
        "\n",
        "    # Validation after each epoch\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for val_batch in validation_dataloader:\n",
        "#             val_input_ids = val_batch[0].to(device)\n",
        "#             val_response_tensor = val_batch[1].to(device)\n",
        "\n",
        "#             val_logits = model(val_input_ids)\n",
        "\n",
        "#             # Compute validation loss\n",
        "#             val_loss = model(val_logits, val_response_tensor)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
        "\n",
        "# Save the final model\n",
        "# filepath = 'trained_model.pth'\n",
        "# torch.save(model.state_dict(), filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ed4606",
      "metadata": {
        "id": "d8ed4606"
      },
      "outputs": [],
      "source": [
        "print(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39f1161",
      "metadata": {
        "id": "f39f1161"
      },
      "outputs": [],
      "source": [
        "response_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92bfdf08",
      "metadata": {
        "id": "92bfdf08"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac71ccd",
      "metadata": {
        "id": "5ac71ccd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}